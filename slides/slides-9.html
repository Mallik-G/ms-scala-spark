<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=UTF-8" http-equiv="Content-Type" />
<meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible" />
<meta content="Asciidoctor 1.5.2" name="generator" />
<title>Spark SQL</title>
<link href="deck.js/themes/style/font.css" rel="stylesheet" />
<style>
.conum { display: inline-block; color: white !important; background-color: #222222; -webkit-border-radius: 100px; border-radius: 100px; text-align: center; width: 1.2em; height: 1.2em; font-size: 0.9em; font-weight: bold; line-height: 1.2; font-family: Arial, sans-serif; font-style: normal; position: relative; top: -0.1em; }
.conum * { color: white !important; }
.conum + b { display: none; }
.conum:after { content: attr(data-value); }
.conum:not([data-value]):empty { display: none; }
.colist table td:first-of-type { padding-right: 0.25em; }
</style>
<style>
/* Stylesheet for CodeRay to match GitHub theme | MIT License | http://foundation.zurb.com */
/*pre.CodeRay {background-color:#f7f7f8;}*/
.CodeRay .line-numbers{border-right:1px solid #d8d8d8;padding:0 0.5em 0 .25em}
.CodeRay span.line-numbers{display:inline-block;margin-right:.5em;color:rgba(0,0,0,.3)}
.CodeRay .line-numbers strong{font-weight: normal}
table.CodeRay{border-collapse:separate;border-spacing:0;margin-bottom:0;border:0;background:none}
table.CodeRay td{vertical-align: top}
table.CodeRay td.line-numbers{text-align:right}
table.CodeRay td.line-numbers>pre{padding:0;color:rgba(0,0,0,.3)}
table.CodeRay td.code{padding:0 0 0 .5em}
table.CodeRay td.code>pre{padding:0}
.CodeRay .debug{color:#fff !important;background:#000080 !important}
.CodeRay .annotation{color:#007}
.CodeRay .attribute-name{color:#000080}
.CodeRay .attribute-value{color:#700}
.CodeRay .binary{color:#509}
.CodeRay .comment{color:#998;font-style:italic}
.CodeRay .char{color:#04d}
.CodeRay .char .content{color:#04d}
.CodeRay .char .delimiter{color:#039}
.CodeRay .class{color:#458;font-weight:bold}
.CodeRay .complex{color:#a08}
.CodeRay .constant,.CodeRay .predefined-constant{color:#008080}
.CodeRay .color{color:#099}
.CodeRay .class-variable{color:#369}
.CodeRay .decorator{color:#b0b}
.CodeRay .definition{color:#099}
.CodeRay .delimiter{color:#000}
.CodeRay .doc{color:#970}
.CodeRay .doctype{color:#34b}
.CodeRay .doc-string{color:#d42}
.CodeRay .escape{color:#666}
.CodeRay .entity{color:#800}
.CodeRay .error{color:#808}
.CodeRay .exception{color:inherit}
.CodeRay .filename{color:#099}
.CodeRay .function{color:#900;font-weight:bold}
.CodeRay .global-variable{color:#008080}
.CodeRay .hex{color:#058}
.CodeRay .integer,.CodeRay .float{color:#099}
.CodeRay .include{color:#555}
.CodeRay .inline{color:#00}
.CodeRay .inline .inline{background:#ccc}
.CodeRay .inline .inline .inline{background:#bbb}
.CodeRay .inline .inline-delimiter{color:#d14}
.CodeRay .inline-delimiter{color:#d14}
.CodeRay .important{color:#555;font-weight:bold}
.CodeRay .interpreted{color:#b2b}
.CodeRay .instance-variable{color:#008080}
.CodeRay .label{color:#970}
.CodeRay .local-variable{color:#963}
.CodeRay .octal{color:#40e}
.CodeRay .predefined{color:#369}
.CodeRay .preprocessor{color:#579}
.CodeRay .pseudo-class{color:#555}
.CodeRay .directive{font-weight:bold}
.CodeRay .type{font-weight:bold}
.CodeRay .predefined-type{color:inherit}
.CodeRay .reserved,.CodeRay .keyword {color:#000;font-weight:bold}
.CodeRay .key{color:#808}
.CodeRay .key .delimiter{color:#606}
.CodeRay .key .char{color:#80f}
.CodeRay .value{color:#088}
.CodeRay .regexp .delimiter{color:#808}
.CodeRay .regexp .content{color:#808}
.CodeRay .regexp .modifier{color:#808}
.CodeRay .regexp .char{color:#d14}
.CodeRay .regexp .function{color:#404;font-weight:bold}
.CodeRay .string{color:#d20}
.CodeRay .string .string .string{background:#ffd0d0}
.CodeRay .string .content{color:#d14}
.CodeRay .string .char{color:#d14}
.CodeRay .string .delimiter{color:#d14}
.CodeRay .shell{color:#d14}
.CodeRay .shell .delimiter{color:#d14}
.CodeRay .symbol{color:#990073}
.CodeRay .symbol .content{color:#a60}
.CodeRay .symbol .delimiter{color:#630}
.CodeRay .tag{color:#008080}
.CodeRay .tag-special{color:#d70}
.CodeRay .variable{color:#036}
.CodeRay .insert{background:#afa}
.CodeRay .delete{background:#faa}
.CodeRay .change{color:#aaf;background:#007}
.CodeRay .head{color:#f8f;background:#505}
.CodeRay .insert .insert{color:#080}
.CodeRay .delete .delete{color:#800}
.CodeRay .change .change{color:#66f}
.CodeRay .head .head{color:#f4f}
</style>
<link href="deck.js/core/deck.core.css" rel="stylesheet" />
<link href="deck.js/extensions/scale/deck.scale.css" media="screen" rel="stylesheet" />
<link href="deck.js/themes/style/datastax.css" media="screen" rel="stylesheet" />
<link href="deck.js/themes/transition/fade.css" media="screen" rel="stylesheet" />
<link href="deck.js/core/print.css" media="print" rel="stylesheet" />
<script src="deck.js/modernizr.custom.js"></script>
</head>
<body class="article">
<div class="deck-container">
<section class="slide" id="title-slide">
<h1>Spark SQL</h1>
</section>
<section class="slide" id="spark-spark-sql-spark-sql-basics">
<h2>Spark SQL</h2>
<div class="paragraph"><p><strong>A relational engine on top of Spark</strong></p></div>
<div class="ulist">
<ul>
<li>Starting point: <em>SQLContext</em></li>
<li>Data representation: DataFrame</li>
<li>Structured queries: SQL, language-integrated queries, HiveQL</li>
</ul>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Spark SQL is a Spark module that is used to query and process structured data.</p></div>
<div class="paragraph"><p><em>SQLContext</em> is an entry point to Spark SQL functionality and is a Cassandra-aware SQL context
available via Spark-Cassandra Connector.</p></div>
<div class="paragraph"><p><em>SQLContext</em> is a Hive-aware SQL context.</p></div>
<div class="paragraph"><p>DataFrames are structured data containers that are alike to tables in relational databases.
DataFrame is the main programming abstraction in Spark SQL.</p></div>
</div>
</div>
</section>
<section class="slide" id="sqlcontext">
<h2>SQLContext</h2>
<div class="listingblock">
<div class="title"><em>Spark shell</em></div>
<div class="content">
<pre class="CodeRay"><code>scala&gt; sqlContext
org.apache.spark.sql.HiveContext</code></pre>
</div>
</div>
<div class="paragraph"><p><br /></p></div>
<div class="listingblock">
<div class="title"><em>Standalone application</em></div>
<div class="content">
<pre class="CodeRay"><code>import org.apache.spark.sql.SQLContext
// ...

val conf = new SparkConf(true)
   .setAppName("SQL Example").setMaster("spark://127.0.0.1:7077")
   .set("spark.cassandra.connection.host", "127.0.0.1")
   .setJars(Array("your-app.jar"))

   val sc = new SparkContext(conf)
   val csc = new SQLContext(sc)</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>This is the main entry point we will use in most cases.</p></div>
<div class="paragraph"><p>A predefined <em>SQLContext</em> object named <em>sqlContext</em> is available in DSE Spark shell.</p></div>
<div class="paragraph"><p>A standalone application needs to initialize its own <em>SQLContext</em> object.</p></div>
<div class="paragraph"><p>Most of our examples use <em>csc</em> in Spark shell.</p></div>
</div>
</div>
</section>
<section class="slide" id="dataframe">
<h2>DataFrame</h2>
<div class="paragraph"><p><strong>Main programming abstraction in Spark SQL</strong></p></div>
<div class="ulist">
<ul>
<li>Distributed collection of data organized into named columns</li>
<li>Similar to a table in a relational database</li>
<li>Has schema, rows, and rich API</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code>scala&gt; val movies = sqlContext.sql("SELECT * FROM killr_video.movies")
movies: org.apache.spark.sql.DataFrame =
[movie_id: uuid, genres: array&lt;string&gt;, rating: float, release_year: int, title: string]</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>DataFrame is a representation of structured dataset that is usually a result of an SQL query.</p></div>
<div class="paragraph"><p>DataFrame has a schema and a rich API that we will discuss in a separate presentation.</p></div>
<div class="paragraph"><p>DataFrame is similar to RDD (also distributed collection of data) but has a different organization to
achieve better performance.</p></div>
<div class="paragraph"><p>The example shows a DataFrame returned by an SQL query.</p></div>
</div>
</div>
</section>
<section class="slide" id="sql-queries">
<h2>SQL Queries</h2>
<div class="paragraph"><p><strong>Declarative approach</strong></p></div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code>sqlContext.sql(" SELECT COUNT(*) AS total         " +
        " FROM killr_video.movies_by_actor " +
        " WHERE actor = 'Johnny Depp'      ")
   .show


   +-----+
   |total|
   +-----+
   |   54|
   +-----+</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>SQL is convenient way to query Cassandra tables!</p></div>
<div class="paragraph"><p>Method <em>sql</em> takes an SQL query and returns a DataFrame with results.
The query returns the number of Johnny Depp&#8217;s movies in our Cassandra database.</p></div>
<div class="paragraph"><p>Action <em>show</em> displays the top 20 rows of DataFrame in a tabular form.</p></div>
</div>
</div>
</section>
<section class="slide" id="language-integrated-queries">
<h2>Language-Integrated Queries</h2>
<div class="paragraph"><p><strong>Functional approach</strong></p></div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code>val movies = sqlContext
    .read
    .format("org.apache.spark.sql.cassandra")
    .options(Map( "keyspace" -&gt; "killr_video", "table" -&gt; "movies_by_actor" ))
    .load

movies.filter("actor = 'Johnny Depp'")
      .agg(Map("*" -&gt; "count"))
      .withColumnRenamed("COUNT(1)", "total")
      .show

   +-----+
   |total|
   +-----+
   |   54|
   +-----+</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Language-integrated queries use various methods of <em>SQLContext</em> (<em>read</em>),
<em>DataFrameReader</em> (<em>format</em>, <em>options</em>, and <em>load</em>), and
<em>DataFrame</em>(<em>filter</em>, <em>agg</em>, <em>withColumnRenamed</em>, and <em>show</em>) to express
the same query as in the previous slide.</p></div>
</div>
</div>
</section>
<section class="slide" id="hiveql-queries">
<h2>HiveQL Queries</h2>
<div class="paragraph"><p><strong>Similar to SQL</strong></p></div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code>sqlContext.sql(" SELECT COUNT(*) AS total         " +
       " FROM killr_video.movies_by_actor " +
       " WHERE actor = 'Johnny Depp'      ")
  .show


   +-----+
   |total|
   +-----+
   |   54|
   +-----+</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>HiveQL is syntactically very similar to SQL.</p></div>
<div class="paragraph"><p>The query returns the number of Johnny Depp&#8217;s movies in our Cassandra database.</p></div>
<div class="paragraph"><p>Action <em>show</em> displays the top 20 rows of DataFrame in a tabular form.</p></div>
</div>
</div>
</section>
<section class="slide" id="spark-spark-sql-dataframe-creating">
<h2>Working with DataFrames</h2>
<div class="paragraph"><p><strong>Structured data processing</strong></p></div>
<div class="ulist">
<ul>
<li><p>
DataFrame<div class="ulist">
<ul>
<li>Distributed collection of data organized into named columns</li>
<li>Similar to a table in a relational database</li>
</ul>
</div></p></li>
<li><p>
Working with DataFrames<div class="ulist">
<ul>
<li><strong>Creating DataFrames</strong></li>
<li>Accessing schema and rows</li>
<li>RDD operations</li>
<li>Language-integrated queries</li>
<li>Saving DataFrames to Cassandra</li>
</ul>
</div></p></li>
</ul>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>DataFrame is a representation of structured dataset that is usually a result of an SQL query.
DataFrame is similar to RDD (also distributed collection of data) but has a different organization to
achieve better performance.</p></div>
<div class="paragraph"><p>DataFrames have a rich API that is categorized in the slide.</p></div>
<div class="paragraph"><p>This presentation discuses how DataFrames are created.</p></div>
</div>
</div>
</section>
<section class="slide" id="creating-a-dataframe-from-an-rdd">
<h2>Creating a DataFrame from an RDD</h2>
<div class="paragraph"><p><strong>Inferring schema using reflection</strong></p></div>
<div class="listingblock">
<div class="title"><em>An RDD of case class objects</em></div>
<div class="content">
<pre class="CodeRay"><code>import sqlContext.implicits._

case class Movie(title: String, year: Int)

val rdd = sc.parallelize(Array( Movie("Alice in Wonderland", 2010), ... ))
// rdd: org.apache.spark.rdd.RDD[Movie]

val df  = rdd.toDF()
// df: org.apache.spark.sql.DataFrame = [title: string, year: int]</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>In this example, we are using function <em>toDF</em> with no arguments. Column names
are inferred from the case class.</p></div>
</div>
</div>
<div style="page-break-after: always"></div>
<div class="paragraph"><p><strong>Inferring schema using reflection</strong></p></div>
<div class="listingblock">
<div class="title"><em>An RDD of tuples</em></div>
<div class="content">
<pre class="CodeRay"><code>import sqlContext.implicits._

val rdd = sc.parallelize(Array( ("Alice in Wonderland", 2010), ... ))
// rdd: org.apache.spark.rdd.RDD[(String, Int)]

val df  = rdd.toDF("title", "year")
// df: org.apache.spark.sql.DataFrame = [title: string, year: int]</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>In this example, we are using function <em>toDF</em> with column names as arguments.</p></div>
</div>
</div>
<div style="page-break-after: always"></div>
<div class="paragraph"><p><strong>Specifying schema programmatically</strong></p></div>
<div class="listingblock">
<div class="title"><em>An RDD of Rows</em></div>
<div class="content">
<pre class="CodeRay"><code>import org.apache.spark.sql.Row
import org.apache.spark.sql.types._

val rdd = sc.parallelize(Array( ("Alice in Wonderland", 2010), ... ))
            .map{case(t,y) =&gt; Row(t,y)}
// rdd: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row]

val schema = StructType( List (
                 StructField("title", StringType,  false),
                 StructField("year",  IntegerType, false) ) )
                 // true = nullable, false = not nullable

val df = sqlContext.createDataFrame(rdd, schema)
// df: org.apache.spark.sql.DataFrame = [title: string, year: int]</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>In this example, we are using method <em>createDataFrame</em> to apply a schema to an RDD of Rows.</p></div>
</div>
</div>
</section>
<section class="slide" id="creating-a-dataframe-from-a-cassandra-table">
<h2>Creating a DataFrame from a Cassandra Table</h2>
<div class="paragraph"><p><strong>Specifying an SQL query</strong></p></div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code>val df = sqlContext.sql("SELECT * FROM killr_video.movies")

// df: org.apache.spark.sql.DataFrame =
// [movie_id: uuid, genres: array&lt;string&gt;, rating: float, release_year: int, title: string]</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Depending on an SQL query, this approach can create a DataFrame based on multiple tables, too.</p></div>
</div>
</div>
<div style="page-break-after: always"></div>
<div class="paragraph"><p><strong>Using <em>DataFrameReader</em></strong></p></div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code>val df = sqlContext.read
            .format("org.apache.spark.sql.cassandra")
            .options(Map( "keyspace" -&gt; "killr_video", "table" -&gt; "movies" ))
            .load

// df: org.apache.spark.sql.DataFrame =
// [movie_id: uuid, genres: array&lt;string&gt;, rating: float, release_year: int, title: string]</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Method <em>read</em> returns a <em>DataFrameReader</em> that is provided with a specific format and options to load data from
Cassandra into a DataFrame.</p></div>
</div>
</div>
</section>
<section class="slide" id="spark-spark-sql-dataframe-schema-rows">
<h2>Working with DataFrames</h2>
<div class="paragraph"><p><strong>Structured data processing</strong></p></div>
<div class="ulist">
<ul>
<li><p>
DataFrame<div class="ulist">
<ul>
<li>Distributed collection of data organized into named columns</li>
<li>Similar to a table in a relational database</li>
</ul>
</div></p></li>
<li><p>
Working with DataFrames<div class="ulist">
<ul>
<li>Creating DataFrames</li>
<li><strong>Accessing schema and rows</strong></li>
<li>RDD operations</li>
<li>Language-integrated queries</li>
<li>Saving DataFrames to Cassandra</li>
</ul>
</div></p></li>
</ul>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>DataFrame is a representation of structured dataset that is usually a result of an SQL query.
DataFrame is similar to RDD (also distributed collection of data) but has a different organization to
achieve better performance.</p></div>
<div class="paragraph"><p>DataFrames have a rich API that is categorized in the slide.</p></div>
<div class="paragraph"><p>This presentation deals with schema and rows in DataFrames.</p></div>
</div>
</div>
</section>
<section class="slide" id="dataframe-schema">
<h2>DataFrame Schema</h2>
<div class="paragraph"><p><strong>Human-readable output</strong></p></div>
<div class="imageblock right" style="float: right">
<div class="content">
<img alt="movies" src="images/spark/spark-sql/dataframe-schema-rows/movies.svg" />
</div>
</div>
<div class="listingblock left">
<div class="content">
<pre class="CodeRay"><code>val df = sqlContext.sql("SELECT * FROM killr_video.movies")
df.printSchema()</code></pre>
</div>
</div>
<div class="listingblock left">
<div class="content">
<pre class="CodeRay"><code>root
 |-- movie_id: uuid (nullable = true)
 |-- genres: array (nullable = true)
 |    |-- element: string (containsNull = true)
 |-- rating: float (nullable = true)
 |-- release_year: integer (nullable = true)
 |-- title: string (nullable = true)</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Method <em>printSchema</em> prints the schema to the console in a tree format.</p></div>
</div>
</div>
<div style="page-break-after: always"></div>
<div class="paragraph"><p><strong>Column names and types</strong></p></div>
<div class="imageblock right" style="float: right">
<div class="content">
<img alt="movies" src="images/spark/spark-sql/dataframe-schema-rows/movies.svg" />
</div>
</div>
<div class="listingblock left">
<div class="content">
<pre class="CodeRay"><code>val df = sqlContext.sql("SELECT * FROM killr_video.movies")
val schema = df.dtypes

// schema: Array[(String, String)] =
//   Array((movie_id,UUIDType),
//         (genres,ArrayType(StringType,true)),
//         (rating,FloatType),
//         (release_year,IntegerType),
//         (title,StringType))</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Method <em>dtypes</em> returns all column names and their data types as an array.</p></div>
</div>
</div>
<div style="page-break-after: always"></div>
<div class="paragraph"><p><strong>Complete schema definition</strong></p></div>
<div class="imageblock right" style="float: right">
<div class="content">
<img alt="movies" src="images/spark/spark-sql/dataframe-schema-rows/movies.svg" />
</div>
</div>
<div class="listingblock left">
<div class="content">
<pre class="CodeRay"><code>val df = sqlContext.sql("SELECT * FROM killr_video.movies")
val schema = df.schema

// schema: org.apache.spark.sql.types.StructType =
//   StructType(StructField(movie_id,UUIDType,true),
//              StructField(genres,ArrayType(StringType,true),true),
//              StructField(rating,FloatType,true),
//              StructField(release_year,IntegerType,true),
//              StructField(title,StringType,true))</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Method <em>schema</em> returns the schema of a DataFrame.</p></div>
</div>
</div>
</section>
<section class="slide" id="dataframe-rows">
<h2>DataFrame Rows</h2>
<div class="paragraph"><p><strong>Accessing primitive values</strong></p></div>
<div class="imageblock right" style="float: right">
<div class="content">
<img alt="movies" src="images/spark/spark-sql/dataframe-schema-rows/movies.svg" />
</div>
</div>
<div class="listingblock left">
<div class="content">
<pre class="CodeRay"><code>val df = sqlContext.sql(" SELECT title, release_year " +
                 " FROM killr_video.movies " +
                 " WHERE title = 'Alice in Wonderland'")
// df: org.apache.spark.sql.DataFrame = [title: string, release_year: int]

val row = df.first
// row: org.apache.spark.sql.Row = [Alice in Wonderland,2010]

println(row(0))          // Alice in Wonderland

println(row.isNullAt(1)) // false

println(row.getInt(1))   // 2010</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Two approaches:</p></div>
<div class="ulist">
<ul>
<li>Using an index of a column in a row</li>
<li>Using getters like getString(i:Int), getInt(i:Int), getDouble(i:Int), etc.</li>
</ul>
</div>
<div class="paragraph"><p>The second approach is less flexible as not all data types may have getters defined (e.g., collection columns).
In addition, only the second approach throws an exception when accessing a null value, so
the use of <em>isNullAt</em> may be required.</p></div>
</div>
</div>
<div style="page-break-after: always"></div>
<div class="paragraph"><p><strong>Accessing complex values</strong></p></div>
<div class="imageblock right" style="float: right">
<div class="content">
<img alt="movies" src="images/spark/spark-sql/dataframe-schema-rows/movies.svg" />
</div>
</div>
<div class="listingblock left">
<div class="content">
<pre class="CodeRay"><code>val df = sqlContext.sql(" SELECT genres " +
                 " FROM killr_video.movies " +
                 " WHERE title = 'Alice in Wonderland'")
// df: org.apache.spark.sql.DataFrame = [genres: array&lt;string&gt;]

val row = df.first
// row: org.apache.spark.sql.Row = [ArrayBuffer(Adventure, Family, Fantasy)]

row(0).asInstanceOf[Seq[String]].foreach(println)
// Adventure
// Family
// Fantasy</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Collection column <em>genres</em> is used as an example.</p></div>
<div class="paragraph"><p><strong>Explicit</strong> type conversion using <em>asInstanceOf</em> is required.</p></div>
</div>
</div>
</section>
<section class="slide" id="spark-spark-sql-dataframe-rdd-operations">
<h2>Working with DataFrames</h2>
<div class="paragraph"><p><strong>Structured data processing</strong></p></div>
<div class="ulist">
<ul>
<li><p>
DataFrame<div class="ulist">
<ul>
<li>Distributed collection of data organized into named columns</li>
<li>Similar to a table in a relational database</li>
</ul>
</div></p></li>
<li><p>
Working with DataFrames<div class="ulist">
<ul>
<li>Creating DataFrames</li>
<li>Accessing schema and rows</li>
<li><strong>RDD operations</strong></li>
<li>Language-integrated queries</li>
<li>Saving DataFrames to Cassandra</li>
</ul>
</div></p></li>
</ul>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>DataFrame is a representation of structured dataset that is usually a result of an SQL query.
DataFrame is similar to RDD (also distributed collection of data) but has a different organization to
achieve better performance.</p></div>
<div class="paragraph"><p>DataFrames have a rich API that is categorized in the slide.</p></div>
<div class="paragraph"><p>This presentation discusses RDD-like operations on DataFrames.</p></div>
</div>
</div>
</section>
<section class="slide" id="repartitioning-and-persistence-transformations">
<h2>Repartitioning and Persistence Transformations</h2>
<div class="paragraph"><p><strong>DataFrame in, DataFrame out</strong></p></div>
<table class="tableblock frame-all grid-all" style="width:100%">
<colgroup>
<col style="width:25%" />
<col style="width:75%" />
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Transformation</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>repartition</strong>(<em>numPartitions</em>)</p></td>
<td class="tableblock halign-left valign-top" rowspan="2"><p class="tableblock">DataFrame repartitioning transformations</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>coalesce</strong>(<em>numPartitions</em>)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>persist</strong>([<em>storageLevel</em>])</p></td>
<td class="tableblock halign-left valign-top" rowspan="3"><p class="tableblock">DataFrame persistence transformations</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>cache</strong>()</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>unpersist</strong>()</p></td>
</tr>
</tbody>
</table>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>The semantics is identical to the corresponding RDD transformations.</p></div>
<div class="paragraph"><p>Similar to RDDs, repartitioning is done to increase or decrease parallelism.
Persistence transformations are used to materialized DataFrames that are reused
by multiple actions to avoid recomputation.</p></div>
</div>
</div>
</section>
<section class="slide" id="dataframe-to-rdd-transformations">
<h2>DataFrame-to-RDD Transformations</h2>
<div class="paragraph"><p><strong>DataFrame in, RDD out</strong></p></div>
<table class="tableblock frame-all grid-all" style="width:100%">
<colgroup>
<col style="width:25%" />
<col style="width:75%" />
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Transformation</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>map</strong>(<em>f</em>)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A new RDD is formed by applying a function <em>f</em> on each row of
the source DataFrame. There is a <em>one-to-one</em> correspondence between DataFrame rows and RDD elements.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>flatMap</strong>(<em>f</em>)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A new RDD is formed by applying a function <em>f</em> on each row of
the source DataFrame. There is a <em>one-to-many</em> correspondence between DataFrame rows and RDD elements
if <em>f</em> returns a collection with more than one element.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>rdd</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A new RDD of rows is formed from the source DataFrame.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>toJSON</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A new RDD of JSON strings is formed by converting rows to JSON in the source DataFrame.</p></td>
</tr>
</tbody>
</table>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>The semantics of <em>map</em> and <em>flatMap</em> is identical to the corresponding RDD transformations.</p></div>
<div class="paragraph"><p>Transformations <em>rdd</em> and <em>toJSON</em> return RDDs of row objects and JSON strings, respectively.</p></div>
</div>
</div>
</section>
<section class="slide" id="dataframe-actions">
<h2>DataFrame Actions</h2>
<div class="paragraph"><p><strong>Triggering computation</strong></p></div>
<table class="tableblock frame-all grid-all" style="width:100%">
<colgroup>
<col style="width:25%" />
<col style="width:75%" />
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Action</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>collect</strong>()</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Returns an <em>Array</em> with all rows of the source DataFrame.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>count</strong>()</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Returns a total number of rows in the source DataFrame.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>first</strong>() or <strong>head</strong>()</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Returns the first row of the source DataFrame.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>take</strong>(<em>n</em>) or <strong>head</strong>(<em>n</em>)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Returns an <em>Array</em> with the first <em>n</em> rows of the source DataFrame.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>show</strong>([<em>n</em>])</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Displays the first <em>n</em> rows of the source DataFrame in a tabular form.
Strings more than 20 characters are truncated.
By default, <em>n</em> = <em>20</em>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>foreach</strong>(<em>f</em>)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Executes a function <em>f</em> on each row of the source DataFrame.
The function usually implements a side effect, such as updating an <em>accumulator</em> variable
or interacting with an external system.</p></td>
</tr>
</tbody>
</table>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Most of these DataFrame actions have RDD counterparts and should be familiar.</p></div>
<div class="paragraph"><p><em>show</em> is probably the most interesting new actions that displays data in a tabular
form, which makes sense for structured data. We will use this action a lot in our examples.</p></div>
</div>
</div>
</section>
<section class="slide" id="example">
<h2>Example</h2>
<div class="paragraph"><p><strong>Counting and displaying Johnny Depp&#8217;s movies</strong></p></div>
<div class="imageblock right" style="float: right">
<div class="content">
<img alt="movies by actor" src="images/spark/spark-sql/dataframe-rdd-operations/movies_by_actor.svg" />
</div>
</div>
<div class="listingblock left">
<div class="content">
<pre class="CodeRay"><code>val df = sqlContext.sql(" SELECT title, release_year, rating " +
                 " FROM killr_video.movies_by_actor " +
                 " WHERE actor = 'Johnny Depp'")
            .coalesce(1).cache
println("Total: " + df.count)
df.show(4)

// Total: 54
// +--------------------+------------+------+
// |               title|release_year|rating|
// +--------------------+------------+------+
// |Pirates of the Ca...|        2017|  null|
// |Alice Through the...|        2016|  null|
// |         Yoga Hosers|        2015|  null|
// |           Mortdecai|        2015|   5.5|
// +--------------------+------------+------+</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>We are using <em>coalesce</em> to decrease the number of partitions to 1 because the dataset
retrieved from Cassandra is tiny and parallelism will not be of much use.</p></div>
<div class="paragraph"><p>We are using <em>cache</em> to materialize and store the DataFrame in main memory because
two actions, <em>count</em> and <em>show</em>, are used.</p></div>
</div>
</div>
</section>
<section class="slide" id="spark-spark-sql-dataframe-language-integrated">
<h2>Working with DataFrames</h2>
<div class="paragraph"><p><strong>Structured data processing</strong></p></div>
<div class="ulist">
<ul>
<li><p>
DataFrame<div class="ulist">
<ul>
<li>Distributed collection of data organized into named columns</li>
<li>Similar to a table in a relational database</li>
</ul>
</div></p></li>
<li><p>
Working with DataFrames<div class="ulist">
<ul>
<li>Creating DataFrames</li>
<li>Accessing schema and rows</li>
<li>RDD operations</li>
<li><strong>Language-integrated queries</strong></li>
<li>Saving DataFrames to Cassandra</li>
</ul>
</div></p></li>
</ul>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>DataFrame is a representation of structured dataset that is usually a result of an SQL query.
DataFrame is similar to RDD (also distributed collection of data) but has a different organization to
achieve better performance.</p></div>
<div class="paragraph"><p>DataFrames have a rich API that is categorized in the slide.</p></div>
<div class="paragraph"><p>This presentation discusses the DataFrame language-intergrated query API.</p></div>
</div>
</div>
</section>
<section class="slide" id="dataframe-query-api">
<h2>DataFrame Query API</h2>
<div class="paragraph"><p><strong>Unary transformations</strong></p></div>
<table class="tableblock frame-all grid-all" style="width:100%">
<colgroup>
<col style="width:25%" />
<col style="width:75%" />
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Transformation</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>select</strong>(<em>columns</em>)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A new DataFrame is formed by selecting a set of <em>columns</em> from the source DataFrame.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>withColumnRenamed</strong>( <em>oldColumn</em>, <em>newColumn</em>)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A new DataFrame is formed by renaming a column in the source DataFrame.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>distinct</strong>()</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A new DataFrame is formed by eliminating duplicate rows in the source DataFrame.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>where</strong>(<em>condition</em>) or <strong>filter</strong>(<em>condition</em>)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A new DataFrame is formed by rows from the source DataFrame that satisfy a <em>condition</em>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>agg</strong>(<em>column-aggregates</em>)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A new DataFrame is formed by applying aggregate functions to columns in the source DataFrame.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>groupBy</strong>(<em>columns</em>)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A new DataFrame is formed by grouping data based on <em>columns</em> in the source DataFrame.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>orderBy</strong>(<em>columns</em>) or <strong>sort</strong>(<em>columns</em>)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A new DataFrame is formed by sorting rows based on <em>columns</em> of the source DataFrame
in the ascending (default) or descending order.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>limit</strong>(<em>n</em>)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A new DataFrame is formed by the first <em>n</em> rows of the source DataFrame.</p></td>
</tr>
</tbody>
</table>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>If DataFrame is equivalent to a table in a relational database, these transformations
is an implementation of the relational algebra.</p></div>
</div>
</div>
<div style="page-break-after: always"></div>
<div class="paragraph"><p><strong>Binary transformations</strong></p></div>
<table class="tableblock frame-all grid-all" style="width:100%">
<colgroup>
<col style="width:25%" />
<col style="width:75%" />
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Transformation</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>join</strong>(<em>otherDF</em>, [<em>condition</em>], [<em>type</em>])</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A new DataFrame is formed by joining the source DataFrame and <em>otherDF</em> based on an optional <em>condition</em>.
The optional join <em>type</em> parameter allows switching between inner (default) and outer joins.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>unionAll</strong>(<em>otherDF</em>)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A new DataFrame is formed by all rows of the source DataFrame and <em>otherDF</em>.
The source DataFrame and <em>otherDF</em> must be union-compatible. Duplicate rows in the result are retained.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>intersect</strong>(<em>otherDF</em>)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A new DataFrame is formed by only those rows that appear in both the source DataFrame and <em>otherDF</em>.
The source DataFrame and <em>otherDF</em> must be union-compatible. Duplicate rows in the result are eliminated.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>except</strong>(<em>otherDF</em>)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A new DataFrame is formed by rows that appear in the source DataFrame but not in <em>otherDF</em>.
The source DataFrame and <em>otherDF</em> must be union-compatible. Duplicate rows in the result are eliminated.</p></td>
</tr>
</tbody>
</table>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>If DataFrame is equivalent to a table in a relational database, these transformations
is an implementation of the relational algebra.</p></div>
</div>
</div>
</section>
<section class="slide" id="supporting-functions">
<h2>Supporting Functions</h2>
<div class="paragraph"><p><strong>import org.apache.spark.sql.functions._</strong></p></div>
<table class="tableblock frame-all grid-all" style="width:100%">
<colgroup>
<col style="width:25%" />
<col style="width:75%" />
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Category</th>
<th class="tableblock halign-left valign-top">Sample functions</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Aggregate functions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>avg</em>, <em>count</em>, <em>max</em>, <em>min</em>, <em>sum</em></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Collection functions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>array_contains</em>, <em>sort_array</em>, <em>size</em></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Date-time functions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>current_date</em>, <em>current_timestamp</em>, <em>second</em>, <em>hour</em>, <em>month</em>, <em>year</em></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Math functions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>ceil</em>, <em>floor</em>, <em>round</em>, <em>pow</em>, <em>sqrt</em>, <em>log</em>, <em>sum</em>, <em>sin</em>, <em>cos</em>, <em>tan</em></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Sorting functions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>asc</em>, <em>desc</em></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">String functions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>concat</em>, <em>length</em>, <em>substring</em>, <em>trim</em></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">UDF functions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>udf</em>, <em>callUDF</em></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Window functions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>denseRank</em>, <em>percentRank</em>, <em>rank</em>, <em>lag</em>, <em>lean</em></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Miscellaneous functions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>col</em>, <em>column</em>, <em>rand</em>, <em>randn</em></p></td>
</tr>
</tbody>
</table>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>There are dozens of those functions that can be imported to your program.
This is a very incomplete list.
We will not be able to cover each one in any great detail.</p></div>
</div>
</div>
</section>
<section class="slide" id="example-2">
<h2>Example</h2>
<div class="paragraph"><p><strong>STEP 1: Creating a DataFrame from a Cassandra table</strong></p></div>
<div class="imageblock right" style="float: right">
<div class="content">
<img alt="movies by actor" src="images/spark/spark-sql/dataframe-language-integrated/movies_by_actor.svg" />
</div>
</div>
<div class="listingblock left">
<div class="content">
<pre class="CodeRay"><code>val df = sqlContext.read
            .format("org.apache.spark.sql.cassandra")
            .options(Map( "keyspace" -&gt; "killr_video",
                          "table" -&gt; "movies_by_actor" ))
            .load</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Creating a DataFrame using <em>DataFrameReader</em>.</p></div>
</div>
</div>
<div style="page-break-after: always"></div>
<div class="paragraph"><p><strong>STEP 2: Executing a language-integrated query</strong></p></div>
<div class="imageblock right" style="float: right">
<div class="content">
<img alt="movies by actor" src="images/spark/spark-sql/dataframe-language-integrated/movies_by_actor.svg" />
</div>
</div>
<div class="listingblock left">
<div class="content">
<pre class="CodeRay"><code>import org.apache.spark.sql.functions._

df.filter("actor = 'Johnny Depp'")
  .groupBy("release_year")
  .agg(Map("*" -&gt; "count", "rating" -&gt; "avg"))
  .withColumnRenamed("COUNT(1)", "total_movies")
  .withColumnRenamed("AVG(rating)", "average_rating")
  .select("release_year", "total_movies", "average_rating")
  .orderBy(desc("total_movies"), desc("average_rating"))
  .limit(3)
  .show

// +------------+------------+-----------------+
// |release_year|total_movies|   average_rating|
// +------------+------------+-----------------+
// |        2004|           4|6.850000023841858|
// |        2000|           3|6.933333396911621|
// |        2011|           3|6.733333269755046|
// +------------+------------+-----------------+</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>We are looking for Johnny Depp&#8217;s 3 most productive years in terms of the number of released movies and
their average ratings.</p></div>
<div class="paragraph"><p>Of course, we could have solved this problem using SQL, but this is a topic of another presentation.</p></div>
</div>
</div>
</section>
<section class="slide" id="spark-spark-sql-dataframe-saving">
<h2>Working with DataFrames</h2>
<div class="paragraph"><p><strong>Structured data processing</strong></p></div>
<div class="ulist">
<ul>
<li><p>
DataFrame<div class="ulist">
<ul>
<li>Distributed collection of data organized into named columns</li>
<li>Similar to a table in a relational database</li>
</ul>
</div></p></li>
<li><p>
Working with DataFrames<div class="ulist">
<ul>
<li>Creating DataFrames</li>
<li>Accessing schema and rows</li>
<li>RDD operations</li>
<li>Language-integrated queries</li>
<li><strong>Saving DataFrames to Cassandra</strong></li>
</ul>
</div></p></li>
</ul>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>DataFrame is a representation of structured dataset that is usually a result of an SQL query.
DataFrame is similar to RDD (also distributed collection of data) but has a different organization to
achieve better performance.</p></div>
<div class="paragraph"><p>DataFrames have a rich API that is categorized in the slide.</p></div>
<div class="paragraph"><p>This presentation discusses how to save a DataFrame into a Cassandra table.</p></div>
</div>
</div>
</section>
<section class="slide" id="running-example">
<h2>Running Example</h2>
<div class="paragraph"><p><strong>Simple ETL scenario</strong></p></div>
<div class="olist arabic">
<ol class="arabic">
<li>
Reading from table <em>movies</em>
</li>
<li>
Filtering movies by genre "Family"
</li>
<li>
Saving into table <em>family_movies</em>
</li>
</ol>
</div>
<div class="imageblock" style="float: center">
<div class="content">
<img alt="challenge" src="images/spark/spark-sql/dataframe-saving/challenge.svg" />
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>We will learn by example.</p></div>
</div>
</div>
</section>
<section class="slide" id="reading-from-a-cassandra-table">
<h2>Reading from a Cassandra Table</h2>
<div class="paragraph"><p><strong>Using <em>DataFrameReader</em></strong></p></div>
<div class="imageblock right" style="float: right">
<div class="content">
<img alt="movies" src="images/spark/spark-sql/dataframe-saving/movies.svg" />
</div>
</div>
<div class="listingblock left">
<div class="content">
<pre class="CodeRay"><code>val movieDF = sqlContext.read
                 .format("org.apache.spark.sql.cassandra")
                 .options(Map( "keyspace" -&gt; "killr_video",
                               "table" -&gt; "movies" ))
                 .load</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Creating a DataFrame using <em>DataFrameReader</em>.</p></div>
</div>
</div>
</section>
<section class="slide" id="filtering-a-dataframe">
<h2>Filtering a DataFrame</h2>
<div class="paragraph"><p><strong>Using language-integrated query API</strong></p></div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code>import org.apache.spark.sql.functions._

val familyDF = movieDF.filter(col("genres").contains("Family"))

familyDF.show

// +--------------------+--------------------+------+------------+--------------------+
// |            movie_id|              genres|rating|release_year|               title|
// +--------------------+--------------------+------+------------+--------------------+
// |3391c072-af52-4d3...|ArrayBuffer(Adven...|  null|        2016|Alice Through the...|
// |87032a77-0ccd-416...|ArrayBuffer(Biogr...|   7.8|        2004|   Finding Neverland|
// |f8ecbd4a-c3e0-41e...|ArrayBuffer(Adven...|   6.5|        2010| Alice in Wonderland|
// |89ccddea-a845-499...|ArrayBuffer(Adven...|   6.7|        2005|Charlie and the C...|
// +--------------------+--------------------+------+------------+--------------------+</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>DataFrame <em>familyDF</em> now contains only family-genre movies.</p></div>
<div class="paragraph"><p>Action <em>show</em> is used to give a preview. We will save <em>familyDF</em> into a Cassandra table next.</p></div>
</div>
</div>
</section>
<section class="slide" id="saving-a-dataframe-into-a-cassandra-table">
<h2>Saving a DataFrame into a Cassandra Table</h2>
<div class="paragraph"><p><strong>Using <em>DataFrameWriter</em></strong></p></div>
<div class="imageblock right" style="float: right">
<div class="content">
<img alt="family movies" src="images/spark/spark-sql/dataframe-saving/family_movies.svg" />
</div>
</div>
<div class="listingblock left">
<div class="content">
<pre class="CodeRay"><code>familyDF.write
        .format("org.apache.spark.sql.cassandra")
        .options(Map( "keyspace" -&gt; "killr_video",
                      "table" -&gt; "family_movies" ))
        .save</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Method <em>write</em> returns a <em>DataFrameWriter</em> that is provided with a specific format and options to save data into
a Cassandra table.</p></div>
</div>
</div>
</section>
<section class="slide" id="spark-spark-sql-querying-cassandra-sql">
<h2>Executing SQL Queries</h2>
<div class="paragraph"><p><strong><em>SQLContext</em> API</strong></p></div>
<table class="tableblock frame-all grid-all" style="width:100%">
<colgroup>
<col style="width:25%" />
<col style="width:75%" />
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Method</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>setKeyspace</strong>(<em>keyspace</em>)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Sets a default Cassandra <em>keyspace</em>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>sql</strong>(<em>query</em>) or <strong>cassandraSql</strong>(<em>query</em>)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Executes an SQL <em>query</em> and returns a DataFrame.</p></td>
</tr>
</tbody>
</table>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>If your program queries one keyspace, it is convenient to use <em>setKeyspace</em>.
Otherwise, qualifying table names with keyspace name would do the job.</p></div>
<div class="paragraph"><p><em>sql</em> and <em>cassandraSql</em> are equivalent.</p></div>
</div>
</div>
<div style="page-break-after: always"></div>
<div class="paragraph"><p><strong><em>DataFrame</em> API</strong></p></div>
<table class="tableblock frame-all grid-all" style="width:100%">
<colgroup>
<col style="width:25%" />
<col style="width:75%" />
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Method</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>registerTempTable</strong>( <em>tableName</em>)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Registers the source DataFrame as a temporary table that can be used in SQL queries by name <em>tableName</em>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>explain</strong>()</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Prints a physical query execution plan to the console.</p></td>
</tr>
</tbody>
</table>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Here are two more useful calls.</p></div>
<div class="paragraph"><p>You can always register a DataFrame as a temporary table that can then be used in SQL queries.
Temporary tables are not stored to Cassandra. They exist in Spark only.</p></div>
<div class="paragraph"><p><em>explain</em> prints a physical query execution plan to the console. You can also access DataFrame&#8217;s property <em>queryExecution</em>
to take a look at a logical execution plan.</p></div>
</div>
</div>
</section>
<section class="slide" id="sql-syntax">
<h2>SQL Syntax</h2>
<div class="paragraph"><p><strong>Simplified grammar</strong></p></div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code>SELECT [DISTINCT] [column-names] | [wildcard]
FROM [kesypace name.]table-name
[JOIN-clause table-name ON join-condition]
[WHERE condition]
[GROUP BY column-names]
[HAVING condition]
[ORDER BY column-names [ASC | DESC]]
[LIMIT number-of-rows]

JOIN-clause --&gt; [JOIN | INNER JOIN | LEFT SEMI JOIN |
LEFT [OUTER] JOIN | RIGHT [OUTER] JOIN | FULL [OUTER] JOIN]

SELECT statement-1
[UNION | UNION ALL | UNION DISTINCT | INTERSECT | EXCEPT]
SELECT statement-2</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>We assume you are familiar with SQL.</p></div>
</div>
</div>
</section>
<section class="slide" id="example-querying-a-cassandra-table">
<h2>Example: Querying a Cassandra Table</h2>
<div class="paragraph"><p><strong>Find the largest rating for Johnny Depp&#8217;s movie</strong></p></div>
<div class="imageblock right" style="float: right">
<div class="content">
<img alt="movies by actor" src="images/spark/spark-sql/querying-cassandra-sql/movies_by_actor.svg" />
</div>
</div>
<div class="listingblock left">
<div class="content">
<pre class="CodeRay"><code>sqlContext.setKeyspace("killr_video")

val maxDF = sqlContext.sql(
    " SELECT actor, MAX(rating) AS max_rating " +
    " FROM movies_by_actor                    " +
    " WHERE actor = 'Johnny Depp'             " +
    " GROUP BY actor                          " )

maxDF.show

// +-----------+----------+
// |      actor|max_rating|
// +-----------+----------+
// |Johnny Depp|       8.6|
// +-----------+----------+</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Simple query over a single table with grouping and aggregation for demonstration purposes.</p></div>
</div>
</div>
</section>
<section class="slide" id="example-querying-a-temporary-table">
<h2>Example: Querying a Temporary Table</h2>
<div class="paragraph"><p><strong>Find Johnny Depp&#8217;s movies with ratings higher than the largest rating - 1</strong></p></div>
<div class="imageblock right" style="float: right">
<div class="content">
<img alt="movies by actor" src="images/spark/spark-sql/querying-cassandra-sql/movies_by_actor.svg" />
</div>
</div>
<div class="listingblock left">
<div class="content">
<pre class="CodeRay"><code>maxDF.registerTempTable("max_rating")

val movieDF = sqlContext.sql(
    " SELECT M.actor, title, release_year, rating    " +
    " FROM max_rating AS R JOIN movies_by_actor AS M " +
    " ON (R.actor = M.actor)                         " +
    " WHERE rating &gt; max_rating - 1                  " +
    " ORDER BY release_year DESC, rating DESC        " )

movieDF.show(2)
// +-----------+--------------------+------------+------+
// |      actor|               title|release_year|rating|
// +-----------+--------------------+------------+------+
// |Johnny Depp|   Finding Neverland|        2004|   7.8|
// |Johnny Depp|Pirates of the Ca...|        2003|   8.1|
// +-----------+--------------------+------------+------+</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>The DataFrame is registered as a temporary table and joined with the Cassandra table.</p></div>
</div>
</div>
</section>
<section class="slide" id="example-query-execution-plan">
<h2>Example: Query Execution Plan</h2>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code>movieDF.explain

// Sample output:
== Physical Plan ==
Project [actor#116,title#121,release_year#117]
 Sort [release_year#117 DESC,rating#120 DESC], true
  Exchange (RangePartitioning 200)
   Project [actor#116,title#121,release_year#117,rating#120]
    Filter (rating#120 &gt; (max_rating#98 - 1.0))
     ShuffledHashJoin [actor#2], [actor#116], BuildRight
      Aggregate false, [actor#2], [actor#2,MAX(PartialMax#123) AS max_rating#98]
       Exchange (HashPartitioning 200)
        Aggregate true, [actor#2], [actor#2,MAX(rating#6) AS PartialMax#123]
         Filter (actor#2 = Johnny Depp)
          PhysicalRDD [actor#2,rating#6], MapPartitionsRDD[202] at explain at &lt;console&gt;:57
      Exchange (HashPartitioning 200)
       PhysicalRDD [rating#120,actor#116,title#121,release_year#117], MapPartitionsRDD[204] at explain at &lt;console&gt;:57</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>This information may be useful if you know how query optimization in Spark works.</p></div>
</div>
</div>
</section>
<section class="slide" id="spark-spark-sql-writing-efficient-sql">
<h2>Predicate Pushdown Optimizations</h2>
<div class="paragraph"><p><strong>Automatic optimizations by <em>Spark-Cassandra Connector</em></strong></p></div>
<div class="ulist">
<ul>
<li>Filtering on a partition key is pushed down to Cassandra</li>
<li>Filtering on a clustering key is pushed down to Cassandra</li>
</ul>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph"><p><em>Spark-Cassandra Connector</em> pushes any predicate that is valid in CQL down to Cassandra.
Choosing the best Cassandra table for a query can substantially improve performance.</p></div>
</td>
</tr>
</table>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p><em>Spark-Cassandra Connector</em> automatically pushs down valid WHERE clauses to Cassandra as long as
the pushdown option is enabled (it is enabled by default).</p></div>
</div>
</div>
</section>
<section class="slide" id="choosing-the-best-table-for-a-query">
<h2>Choosing the Best Table for a Query</h2>
<div class="paragraph"><p><strong>One query, two tables</strong></p></div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code>SELECT release_year, title
FROM killr_video.???
WHERE actor = 'Johnny Depp' AND release_year &lt; 2015
ORDER BY release_year DESC</code></pre>
</div>
</div>
<div class="imageblock" style="float: left">
<div class="content">
<img alt="schema" src="images/spark/spark-sql/writing-efficient-sql/schema.svg" />
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Query: Find release years and titles of Johnny Depp&#8217;s movies released before 2015 and show results
in descending release year order.</p></div>
<div class="paragraph"><p>The query is expressed in SQL with the ??? placeholder for a table name.</p></div>
<div class="paragraph"><p>Both tables can be used to answer the query. Which one will you choose?
Pay attention to table partition and clustering keys.</p></div>
<div class="paragraph"><p>Understanding the Cassandra data and query models is very important!</p></div>
</div>
</div>
</section>
<section class="slide" id="clustering-key-predicate-can-be-pushed">
<h2>Clustering Key Predicate can be Pushed</h2>
<div class="paragraph"><p><strong>actor = 'Johnny Depp'</strong></p></div>
<div class="imageblock right" style="float: right">
<div class="content">
<img alt="actors by movie" src="images/spark/spark-sql/writing-efficient-sql/actors_by_movie.svg" />
</div>
</div>
<div class="listingblock left">
<div class="title"><em>SQL query</em></div>
<div class="content">
<pre class="CodeRay"><code>sqlContext.sql(" SELECT release_year, title " +
        " FROM killr_video.actors_by_movie " +
        " WHERE actor = 'Johnny Depp' AND release_year &lt; 2015 " +
        " ORDER BY release_year DESC").show</code></pre>
</div>
</div>
<div class="listingblock left">
<div class="title"><em>Language-integrated query</em></div>
<div class="content">
<pre class="CodeRay"><code>import org.apache.spark.sql.functions._
val df = sqlContext.read.format("org.apache.spark.sql.cassandra")
            .options(Map( "keyspace" -&gt; "killr_video",
                          "table" -&gt; "actors_by_movie" )).load
df.filter("actor = 'Johnny Depp' AND release_year &lt; 2015")
  .select("release_year", "title")
  .orderBy(desc("release_year")).show</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Both SQL and language-integrated queries are equivalent. They return equivalent but
not necessarily identical results: ordering of rows within the same year group may be different.</p></div>
<div class="paragraph"><p>This is not the best table choice.</p></div>
<div class="paragraph"><p>Even though <em>actor = 'Johnny Depp'</em> can be pushed down to Cassandra, the query is still
expensive because Cassandra will have to retrieve matching rows from many partitions.
Once results are delivered from Cassandra, Spark still has to filter based on <em>release_year &lt; 2015</em>
and perform sorting.</p></div>
</div>
</div>
</section>
<section class="slide" id="all-predicates-can-be-pushed">
<h2>All Predicates can be Pushed</h2>
<div class="paragraph"><p><strong>actor = 'Johnny Depp' AND release_year &lt; 2015</strong></p></div>
<div class="imageblock right" style="float: right">
<div class="content">
<img alt="movies by actor" src="images/spark/spark-sql/writing-efficient-sql/movies_by_actor.svg" />
</div>
</div>
<div class="listingblock left">
<div class="title"><em>SQL query</em></div>
<div class="content">
<pre class="CodeRay"><code>sqlContext.sql(" SELECT release_year, title " +
        " FROM killr_video.movies_by_actor " +
        " WHERE actor = 'Johnny Depp' AND release_year &lt; 2015").show</code></pre>
</div>
</div>
<div class="listingblock left">
<div class="title"><em>Language-integrated query</em></div>
<div class="content">
<pre class="CodeRay"><code>val df = sqlContext.read.format("org.apache.spark.sql.cassandra")
            .options(Map( "keyspace" -&gt; "killr_video",
                          "table" -&gt; "movies_by_actor" )).load
df.filter("actor = 'Johnny Depp' AND release_year &lt; 2015")
  .select("release_year", "title").show</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Better table choice = faster and simpler query!</p></div>
<div class="paragraph"><p>Much better performance: the whole WHERE clause can be pushed down to Cassandra;
Cassandra will access only one partition very efficiently.</p></div>
<div class="paragraph"><p>Simpler query: because data in the Cassandra partition for Johnny Depp is already ordered
by clustering column <em>release_year</em>, no need to use ORDER BY.</p></div>
</div>
</div>
</section>
<section class="slide" id="sample-output">
<h2>Sample Output</h2>
<div class="paragraph"><p><strong>All queries return equivalent results</strong></p></div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code>+------------+--------------------+
|release_year|               title|
+------------+--------------------+
|        2014|       Transcendence|
|        2014|      Into the Woods|
|        2014|                Tusk|
|        2013|          Lucky Them|
|        2013|     The Lone Ranger|
|        2012|        Dark Shadows|
|        2011|               Rango|
|        2011|       The Rum Diary|
|        2011|Pirates of the Ca...|
|        2010|         The Tourist|
|        2010| Alice in Wonderland|
|        2009|The Imaginarium o...|
|        2009|      Public Enemies|
|        2007|Pirates of the Ca...|
|        2007|Sweeney Todd: The...|
|        2006|Pirates of the Ca...|
|        2005|Charlie and the C...|
|        2004|       The Libertine|
|        2004|       Secret Window|
|        2004|   Finding Neverland|
+------------+--------------------+</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>The four queries return equivalent but
not necessarily identical results: ordering of rows within the same year group may be different.</p></div>
<div class="paragraph"><p>The outputs are equivalent, the response times are not!</p></div>
</div>
</div>
</section>
<div aria-role="navigation">
<a class="deck-prev-link" href="#" title="Previous">
<i class="icon-chevron-with-circle-left"></i>
</a>
<a class="deck-next-link" href="#" title="Next">
<i class="icon-chevron-with-circle-right"></i>
</a>
</div>
</div>
<script src="deck.js/jquery.min.js"></script>
<script src="deck.js/d3.v2.js"></script>
<script src="deck.js/jquery-ui.min.js"></script>
<script src="deck.js/core/deck.core.js"></script>
<script src="deck.js/extensions/scale/deck.scale.js"></script>
<script src="deck.js/extensions/navigation/deck.navigation.js"></script>
<script src="deck.js/extensions/split/deck.split.js"></script>
<script src="deck.js/extensions/animation/deck.animation.js"></script>
<script src="deck.js/extensions/deck.js-notes/deck.notes.js"></script>
<script src="deck.js/extensions/goto/deck.goto.js"></script>
<script src="deck.js/extensions/clone/deck.clone.js"></script>
<script src="deck.js/extensions/svg/svg.min.js"></script>
<script src="js/course.js"></script>
<footer>
<div class="flex-element deck-course">
<p>&copy; 2016 DataStax. Use only with permission. &bull;
<span class="course-title">Spark SQL</span></p>
</div>
<div class="flex-element deck-brand">
<a href="http://academy.datastax.com" target="blank">DataStax Academy</a>
</div>
<div class="deck-progressbar">
<span></span>
</div>
</footer>
<script type="text/javascript">
  //<![CDATA[
    (function($, deck, undefined) {
      $.deck.defaults.keys['previous'] = [8, 33, 37, 39];
      $.deck.defaults.keys['next'] = [13, 32, 34, 39];
    
      $.extend(true, $[deck].defaults, {
          countNested: false
      });
    
      $.deck('.slide');
      $.deck('disableScale');
    })(jQuery, 'deck');
  //]]>
</script>
<script type="text/javascript">
  //<![CDATA[
    $(document).bind('deck.change', function(event, from, to) {
      var width = to / ($.deck('getSlides').length - 1) * 100;
      $('.deck-progressbar span').css('width', width + '%');
    });
  //]]>
</script>
</body>
</html>